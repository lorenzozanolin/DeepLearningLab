{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a82afc5e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Fine-Tuning\n",
    "\n",
    "Reusing already pre-trained Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc51f71",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aba69a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We may not always have enough data to train/computing resource from scratch a large model\n",
    "\n",
    "One solution, aside from the obvious costly and time consuming data collection step, is to re-use part of state of the art neural network train on large scale dataset (usually ImageNet)  \n",
    "The idea is to reuse the feature learned on a very general dataset and *fine-tune* them for a problem specific dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f1c2ff",
   "metadata": {},
   "source": [
    "This technique is called *transfer learning*, we transfer the knowledge learned from the source dataset to the target dataset  \n",
    "The usual way to do it, is by copying all except the output layer (i.e., the layer that classify things based on the feature extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1d44fc",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src='images/finetune.svg' />\n",
    "    <p>Source: <a href='http://d2l.ai'>d2l.ai</a></p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181e11d7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "When applying fine-tuning, we update the weights of the pre-trained neural network to better fit the new dataset  \n",
    "\n",
    "Another technique, called *feature extraction* block the weights of the pre-trained layer, only training the output layer. If your datasets are very similar, you might get good result from this with a low training cost   \n",
    "\n",
    "However, in practice it is often common the first the first layer and only train the last layers of the pre-trained neural network. A good intuition behind this, is that the first convolution layer learn very generic features while deeper ones learns more class specific features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1a2736",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pytorch contains already pre-trained state of the art neural networks for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4de5fa9",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_net = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "263e7abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_net.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f4d6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIf you only want to train the head of the network\\nfor param in pretrained_net.parameters():\\n    param.requires_grad = False\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "If you only want to train the head of the network\n",
    "for param in pretrained_net.parameters():\n",
    "    param.requires_grad = False\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2276df",
   "metadata": {},
   "source": [
    "ImageNet-1000 contains 1000 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "404288d1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "bs = 32\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=8)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=bs*2, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5329b947",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We then simply swap the head with a `Linear` layer of the correct output shape that we initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bce3170",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_net.fc = nn.Linear(pretrained_net.fc.in_features, 10)\n",
    "nn.init.xavier_normal_(pretrained_net.fc.weight)\n",
    "nn.init.constant_(pretrained_net.fc.bias, 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fac8ca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we have a GPU, we use it  \n",
    "`DataParallel` allows to use multiple GPU in parallel if we have them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c93f5105",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "pretrained_net = pretrained_net.to(device)\n",
    "if device == 'cuda':\n",
    "    pretrained_net = torch.nn.DataParallel(net) # if multiple GPUs use them\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = torch.optim.AdamW(pretrained_net.parameters(), lr=1e-4, weight_decay=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, verbose=True, min_lr=1e-5, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6627353",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">valiant-donkey-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ingambe/pretraining-resnet18\" target=\"_blank\">https://wandb.ai/ingambe/pretraining-resnet18</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ingambe/pretraining-resnet18/runs/2d4uccvf\" target=\"_blank\">https://wandb.ai/ingambe/pretraining-resnet18/runs/2d4uccvf</a><br/>\n",
       "                Run data is saved locally in <code>/home/ingambe/DeepLearningCourse/5-Computer-vision/Slides/wandb/run-20211127_213857-2d4uccvf</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6527192f184b95873aa7cad1ff1012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3d77899c254a5eb115daaf3f5208c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1563.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e44b27afdacb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Backward pass to compute the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# of loss w.r.t our learnable params.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Update params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"pretraining-resnet18\")\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "epochs = 10\n",
    "for epoch in trange(epochs):\n",
    "    accurate = 0\n",
    "    total = 0\n",
    "    losses = 0\n",
    "    for X, y in tqdm(trainloader):\n",
    "        y_pred = pretrained_net(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        score, predicted = torch.max(y_pred, 1)\n",
    "        accurate += (y == predicted).sum().float()\n",
    "        losses += loss.item()\n",
    "        total += len(y)\n",
    "\n",
    "        # zero the gradients before running\n",
    "        # the backward pass.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass to compute the gradient\n",
    "        # of loss w.r.t our learnable params. \n",
    "        loss.backward()\n",
    "\n",
    "        # Update params\n",
    "        optimizer.step()\n",
    "    \n",
    "    wandb.log({\n",
    "            'loss': losses / len(trainloader),\n",
    "            'accuracy': accurate / total\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff200c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
