{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40212943",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Weights & Biases\n",
    "\n",
    "Linear regression with better tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a87aef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9486798e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's define the hyper parameters used for training so we can log them and keep track of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d629d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ingambe/example/runs/180qkh0f\" target=\"_blank\">peach-energy-14</a></strong> to <a href=\"https://wandb.ai/ingambe/example\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/ingambe/example/runs/180qkh0f?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x13eb3c8e0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "epochs = 2000\n",
    "wandb.init(project=\"example\", config={\"lr\": lr, \"epochs\": epochs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4874046a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As before, let's generate some synthetic data and train on it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f379ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-15.5195,   4.9580,  13.6744,   1.0959,   1.6048,   7.6192, -12.1037,\n",
       "          -2.5858,   4.8203,  -3.3834]),\n",
       " tensor([2.5000, 4.8000]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_W = torch.Tensor([2.5, 4.8])\n",
    "input_data = torch.randn((10, 2))\n",
    "ground_truth = torch.matmul(input_data, true_W)\n",
    "ground_truth, true_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a09c9062",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "random_weights = torch.randn((2), requires_grad=True)\n",
    "criterion = nn.MSELoss()\n",
    "for i in range(epochs):\n",
    "    prediction = torch.matmul(input_data, random_weights)\n",
    "    loss = criterion(prediction, ground_truth)\n",
    "    loss.backward()\n",
    "    # Why do we need to remove the gradient computation here ?\n",
    "    with torch.no_grad():\n",
    "        random_weights = random_weights - lr * random_weights.grad\n",
    "        wandb.log({'loss': loss.item()})\n",
    "    random_weights.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbb6568",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can even plot the histogram of the weights, this is usefull to know the importance of each input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd7db551",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"weight_1\", \"weight_2\"]\n",
    "data = [[label, val] for (label, val) in zip(labels, random_weights.detach().numpy())]\n",
    "table = wandb.Table(data=data, columns = [\"label\", \"value\"])\n",
    "wandb.log({\"learned_weights\" : wandb.plot.bar(table, \"label\",\n",
    "                               \"value\", title=\"Output weights\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad08b7da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
