{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3acf2ccd",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Advanced torch.nn\n",
    "\n",
    "Sometimes Sequential is not enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8d02731",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "226bb5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "myLogisticRegression = nn.Sequential(\n",
    "    nn.Linear(10, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754f0694",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sequential is basicaly a for loop over the modules\n",
    "\n",
    "But sometimes, we want to have other operation and have control on the order of execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa5bd8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__() # never forget to call the super method !!\n",
    "        self.ln = nn.Linear(5, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_transformed = self.ln(x)\n",
    "        # here I can do other thing\n",
    "        x = x + x_transformed\n",
    "        return F.softmax(x, dim=1) # dim0 is batch, dim1 is input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09be2dfd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2618, 0.1978, 0.1257, 0.2389, 0.1758],\n",
       "        [0.1616, 0.1834, 0.2019, 0.2840, 0.1691],\n",
       "        [0.1175, 0.2497, 0.1860, 0.3224, 0.1244],\n",
       "        [0.2282, 0.1938, 0.1163, 0.2827, 0.1790],\n",
       "        [0.1818, 0.1809, 0.1543, 0.3685, 0.1146],\n",
       "        [0.1777, 0.2839, 0.1170, 0.2292, 0.1922],\n",
       "        [0.2214, 0.2467, 0.1339, 0.2728, 0.1253],\n",
       "        [0.1611, 0.1796, 0.1727, 0.2707, 0.2160],\n",
       "        [0.1769, 0.1617, 0.1354, 0.3470, 0.1789],\n",
       "        [0.1230, 0.1565, 0.1267, 0.3385, 0.2553],\n",
       "        [0.1623, 0.2321, 0.2125, 0.2832, 0.1098],\n",
       "        [0.1266, 0.1913, 0.1647, 0.3520, 0.1653],\n",
       "        [0.1319, 0.1559, 0.1844, 0.4048, 0.1229],\n",
       "        [0.1183, 0.2131, 0.1768, 0.4055, 0.0864],\n",
       "        [0.1958, 0.1828, 0.1387, 0.2577, 0.2250],\n",
       "        [0.2229, 0.1732, 0.1915, 0.3410, 0.0714],\n",
       "        [0.2356, 0.1670, 0.1682, 0.2518, 0.1774],\n",
       "        [0.1836, 0.2537, 0.1075, 0.2534, 0.2018],\n",
       "        [0.1873, 0.3138, 0.1585, 0.2523, 0.0881],\n",
       "        [0.1270, 0.1392, 0.1795, 0.4282, 0.1262],\n",
       "        [0.1493, 0.2168, 0.1702, 0.3973, 0.0663],\n",
       "        [0.1760, 0.1334, 0.2024, 0.3927, 0.0954],\n",
       "        [0.1980, 0.1700, 0.1294, 0.2625, 0.2401],\n",
       "        [0.1200, 0.1102, 0.1018, 0.2984, 0.3697],\n",
       "        [0.1422, 0.1859, 0.1581, 0.3665, 0.1474],\n",
       "        [0.1842, 0.1878, 0.1129, 0.2736, 0.2415],\n",
       "        [0.1903, 0.2725, 0.1188, 0.2968, 0.1215],\n",
       "        [0.1407, 0.1724, 0.1215, 0.3687, 0.1967],\n",
       "        [0.1716, 0.1185, 0.1683, 0.4129, 0.1287],\n",
       "        [0.1568, 0.2186, 0.2052, 0.2804, 0.1390],\n",
       "        [0.1387, 0.1026, 0.1729, 0.3974, 0.1884],\n",
       "        [0.1563, 0.2012, 0.1268, 0.3814, 0.1343]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = torch.rand((32, 5))\n",
    "my_model = Model()\n",
    "my_model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff7a50f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Functions such as Softmax can be used throught `torch.nn.functional` or with modules `torch.nn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4afb0ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class ModuleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModuleModel, self).__init__()\n",
    "        self.ln = nn.Linear(5, 5)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_transformed = self.ln(x)\n",
    "        # here I can do other things\n",
    "        if random.randint(0, 1) % 2 == 0:\n",
    "            x = x + x_transformed\n",
    "        else:\n",
    "            x = x_transformed * 2\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98f91196",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1708, 0.0426, 0.2399, 0.0541, 0.4927],\n",
       "        [0.1737, 0.0598, 0.1755, 0.0685, 0.5226],\n",
       "        [0.2524, 0.0643, 0.3401, 0.1343, 0.2090],\n",
       "        [0.3348, 0.0664, 0.1403, 0.1950, 0.2635],\n",
       "        [0.3251, 0.0637, 0.1101, 0.1901, 0.3109],\n",
       "        [0.2724, 0.0610, 0.1158, 0.1387, 0.4122],\n",
       "        [0.1968, 0.1066, 0.1936, 0.1086, 0.3945],\n",
       "        [0.2672, 0.0763, 0.1744, 0.1163, 0.3658],\n",
       "        [0.2339, 0.0610, 0.2806, 0.1026, 0.3220],\n",
       "        [0.2262, 0.0678, 0.0810, 0.1377, 0.4873],\n",
       "        [0.4135, 0.0328, 0.1640, 0.1812, 0.2086],\n",
       "        [0.2891, 0.0511, 0.2637, 0.1158, 0.2804],\n",
       "        [0.3054, 0.0494, 0.1679, 0.1380, 0.3393],\n",
       "        [0.2943, 0.0869, 0.1336, 0.1912, 0.2940],\n",
       "        [0.2649, 0.0759, 0.2906, 0.1502, 0.2183],\n",
       "        [0.1958, 0.1027, 0.1811, 0.1056, 0.4147],\n",
       "        [0.3074, 0.0701, 0.1679, 0.1588, 0.2958],\n",
       "        [0.2796, 0.0564, 0.2682, 0.1449, 0.2510],\n",
       "        [0.2515, 0.0699, 0.1303, 0.1188, 0.4295],\n",
       "        [0.2914, 0.0430, 0.1344, 0.1170, 0.4143],\n",
       "        [0.1935, 0.0851, 0.1490, 0.0976, 0.4748],\n",
       "        [0.2325, 0.0684, 0.1009, 0.1288, 0.4694],\n",
       "        [0.2587, 0.1048, 0.1610, 0.1901, 0.2854],\n",
       "        [0.2542, 0.1030, 0.1718, 0.1510, 0.3200],\n",
       "        [0.2064, 0.0551, 0.2603, 0.0850, 0.3933],\n",
       "        [0.3602, 0.0334, 0.1185, 0.1433, 0.3446],\n",
       "        [0.3780, 0.0245, 0.0961, 0.1438, 0.3576],\n",
       "        [0.2775, 0.0726, 0.0779, 0.1869, 0.3851],\n",
       "        [0.3322, 0.0321, 0.2016, 0.1214, 0.3128],\n",
       "        [0.2305, 0.0598, 0.2419, 0.0950, 0.3728],\n",
       "        [0.2539, 0.0355, 0.1398, 0.0845, 0.4863],\n",
       "        [0.2891, 0.0671, 0.2112, 0.1245, 0.3082]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = torch.rand((32, 5))\n",
    "my_module_model = ModuleModel()\n",
    "my_module_model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d043b8b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can leverage the parallelism power of GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2f01f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if a GPU with Cuda capacities is available\n",
    "if torch.cuda.is_available():\n",
    "    # put the model on the GPU\n",
    "    my_module_model = my_module_model.to('cuda')\n",
    "    print('Training on GPU!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f33a9506",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1708, 0.0426, 0.2399, 0.0541, 0.4927],\n",
       "        [0.1737, 0.0598, 0.1755, 0.0685, 0.5226],\n",
       "        [0.2524, 0.0643, 0.3401, 0.1343, 0.2090],\n",
       "        [0.3348, 0.0664, 0.1403, 0.1950, 0.2635],\n",
       "        [0.3251, 0.0637, 0.1101, 0.1901, 0.3109],\n",
       "        [0.2724, 0.0610, 0.1158, 0.1387, 0.4122],\n",
       "        [0.1968, 0.1066, 0.1936, 0.1086, 0.3945],\n",
       "        [0.2672, 0.0763, 0.1744, 0.1163, 0.3658],\n",
       "        [0.2339, 0.0610, 0.2806, 0.1026, 0.3220],\n",
       "        [0.2262, 0.0678, 0.0810, 0.1377, 0.4873],\n",
       "        [0.4135, 0.0328, 0.1640, 0.1812, 0.2086],\n",
       "        [0.2891, 0.0511, 0.2637, 0.1158, 0.2804],\n",
       "        [0.3054, 0.0494, 0.1679, 0.1380, 0.3393],\n",
       "        [0.2943, 0.0869, 0.1336, 0.1912, 0.2940],\n",
       "        [0.2649, 0.0759, 0.2906, 0.1502, 0.2183],\n",
       "        [0.1958, 0.1027, 0.1811, 0.1056, 0.4147],\n",
       "        [0.3074, 0.0701, 0.1679, 0.1588, 0.2958],\n",
       "        [0.2796, 0.0564, 0.2682, 0.1449, 0.2510],\n",
       "        [0.2515, 0.0699, 0.1303, 0.1188, 0.4295],\n",
       "        [0.2914, 0.0430, 0.1344, 0.1170, 0.4143],\n",
       "        [0.1935, 0.0851, 0.1490, 0.0976, 0.4748],\n",
       "        [0.2325, 0.0684, 0.1009, 0.1288, 0.4694],\n",
       "        [0.2587, 0.1048, 0.1610, 0.1901, 0.2854],\n",
       "        [0.2542, 0.1030, 0.1718, 0.1510, 0.3200],\n",
       "        [0.2064, 0.0551, 0.2603, 0.0850, 0.3933],\n",
       "        [0.3602, 0.0334, 0.1185, 0.1433, 0.3446],\n",
       "        [0.3780, 0.0245, 0.0961, 0.1438, 0.3576],\n",
       "        [0.2775, 0.0726, 0.0779, 0.1869, 0.3851],\n",
       "        [0.3322, 0.0321, 0.2016, 0.1214, 0.3128],\n",
       "        [0.2305, 0.0598, 0.2419, 0.0950, 0.3728],\n",
       "        [0.2539, 0.0355, 0.1398, 0.0845, 0.4863],\n",
       "        [0.2891, 0.0671, 0.2112, 0.1245, 0.3082]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_module_model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fd4fea",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This will crash (**if you have a CUDA GPU**). Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612afe9a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We've put the model on the GPU but the batch is on the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36f6c621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(next(my_module_model.parameters()).device)\n",
    "print(batch.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d7cc8f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The solution is simply to move the batch to the GPU before passing the data to the model\n",
    "\n",
    "**Clean way to do it:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5143710f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.1526e-01, 8.7074e-01, 7.6456e-01, 8.0506e-01, 1.8693e-01],\n",
       "        [2.7996e-01, 5.5058e-01, 6.3251e-01, 4.7868e-01, 8.7997e-02],\n",
       "        [2.0897e-01, 7.1913e-01, 3.4556e-02, 7.7303e-01, 9.7798e-01],\n",
       "        [7.1657e-01, 6.4428e-01, 4.6273e-01, 1.1385e-01, 9.6753e-01],\n",
       "        [4.3807e-01, 7.1147e-02, 3.8300e-01, 2.0679e-01, 6.7220e-01],\n",
       "        [6.1677e-01, 7.4780e-01, 8.2767e-01, 1.1967e-01, 7.4780e-01],\n",
       "        [1.8971e-01, 3.4026e-01, 1.4341e-01, 1.4436e-01, 1.7825e-01],\n",
       "        [9.3474e-01, 5.3825e-01, 3.7738e-01, 2.2789e-02, 1.4459e-01],\n",
       "        [3.9991e-01, 7.9361e-01, 3.6654e-01, 6.4011e-01, 6.2002e-01],\n",
       "        [1.4891e-01, 4.8677e-01, 8.7762e-01, 7.5507e-02, 7.5744e-01],\n",
       "        [6.8368e-01, 2.1135e-02, 2.8277e-01, 8.2078e-01, 8.2123e-01],\n",
       "        [8.1512e-01, 8.5075e-01, 4.2459e-01, 5.6651e-01, 6.5530e-01],\n",
       "        [6.5198e-01, 7.3676e-01, 6.8148e-01, 4.6406e-01, 8.2393e-01],\n",
       "        [3.5115e-01, 1.7240e-01, 1.9470e-01, 8.2418e-02, 6.5621e-01],\n",
       "        [4.0990e-01, 8.5744e-01, 1.1644e-01, 4.6744e-01, 9.9223e-01],\n",
       "        [2.0932e-01, 3.2720e-01, 2.0096e-01, 1.3355e-01, 1.4442e-01],\n",
       "        [8.7108e-01, 8.7599e-01, 5.2217e-01, 7.0643e-02, 8.0234e-01],\n",
       "        [1.5699e-01, 5.2853e-01, 2.0522e-01, 8.2024e-01, 9.6317e-01],\n",
       "        [7.4786e-01, 7.0575e-01, 6.9930e-01, 1.0580e-02, 4.2305e-01],\n",
       "        [8.1153e-01, 7.8933e-01, 9.2982e-01, 3.8161e-01, 6.6251e-01],\n",
       "        [1.7281e-01, 2.3093e-01, 3.7301e-01, 2.0890e-01, 9.4808e-02],\n",
       "        [4.4393e-01, 8.5913e-01, 9.4214e-01, 1.4476e-02, 7.9423e-01],\n",
       "        [5.6009e-03, 1.9008e-01, 4.5892e-02, 1.7422e-01, 7.6492e-01],\n",
       "        [4.1178e-01, 2.6893e-01, 8.9819e-02, 3.3114e-02, 3.6554e-01],\n",
       "        [6.6048e-04, 2.4656e-01, 2.6881e-01, 9.1022e-01, 2.7422e-01],\n",
       "        [6.8323e-01, 7.2591e-02, 6.6697e-01, 6.5100e-01, 5.4850e-01],\n",
       "        [6.9226e-01, 1.7633e-01, 9.5283e-01, 7.7544e-01, 7.7875e-01],\n",
       "        [1.9607e-01, 1.1177e-01, 5.8588e-01, 2.5776e-02, 7.4608e-01],\n",
       "        [5.8201e-01, 3.8160e-01, 5.7865e-01, 9.6056e-01, 6.8350e-01],\n",
       "        [1.9395e-01, 4.5318e-02, 1.3869e-01, 7.4906e-01, 9.2082e-02],\n",
       "        [7.3697e-01, 6.0825e-01, 9.5935e-01, 5.9327e-01, 3.3030e-01],\n",
       "        [9.0423e-01, 5.9399e-01, 3.1226e-01, 2.3013e-01, 3.4700e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #0, first GPU if multiple one\n",
    "my_module_model.to(device)\n",
    "batch.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0df9ea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Performance trick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1646a161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    batch.to(device, non_blocking=True) # doesn't lock the program while waiting for batch to be put on GPU\n",
    "    print(f'iteration {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52afbcc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## But Pierre, how do I init the layers? You said it's important....\n",
    "\n",
    "## Glad you asked!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a9dce9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Writing a module makes it easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a95ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_my_layer(m):\n",
    "    torch.nn.init.xavier_normal_(m.weight)\n",
    "    torch.nn.init.constant_(m.bias, 0)\n",
    "    return m\n",
    "\n",
    "class MyInitLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModuleModel, self).__init__()\n",
    "        self.ln = init_my_layer(nn.Linear(5, 5))\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ln(x)\n",
    "        return self.softmax(x)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
