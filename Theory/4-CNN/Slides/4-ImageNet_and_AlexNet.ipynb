{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57a1f1c2",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# ImageNet and AlexNet\n",
    "\n",
    "A turning point in the history of deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d098b411",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*ImageNet* is one of the largest image dataset used as a metric to evaluate state of the art NN architectures  \n",
    "14 million images and 1000 categories. We often report the top 5-accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec1c23b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntorchvision.datasets.ImageNet(root='./imageNet', split='train', \\n                              transform=torchvision.transforms.Compose([\\n                                  torchvision.transforms.ToTensor(),\\n                                  transforms.Normalize(mean=[0.485, 0.456, 0.406],\\n                                 std=[0.229, 0.224, 0.225])], download=True)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't execute unless you have a good bandwidth and enough hard drive space (150GB)\n",
    "# Update: ImageNet is not available to download from torchvision directly. It needs to be downloaded by hand\n",
    "'''\n",
    "torchvision.datasets.ImageNet(root='./imageNet', split='train', \n",
    "                              transform=torchvision.transforms.Compose([\n",
    "                                  torchvision.transforms.ToTensor(),\n",
    "                                  transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])], download=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14028517",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In 2012, Alex Krizhevsky, Ilya Sutskever and Geoffrey Hinton proposed a CNN architecture and implemented it on Cuda GPUs to compete in the *ImageNet* competition\n",
    "\n",
    "<center>\n",
    "    <img src='images/Comparison_image_neural_networks.png' width=55% style=\"margin-left:auto; margin-right:auto\"/>\n",
    "    <p style=\"font-size:14px;\">Source: <a href='https://en.wikipedia.org/wiki/AlexNet'>Wikipedia</a></p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e6a604",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "TODO: Based on the right end of the diagram, implement the AlexNet architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94d28683",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 96, 11, stride=4)\n",
    "        self.maxPool = nn.MaxPool2d(3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(96, 256, 5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(256, 384, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(384, 384, 3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(384, 256, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(5 * 5 * 256, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 1000)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.maxPool(self.relu(self.conv1(x)))\n",
    "        x = self.maxPool(self.relu(self.conv2(x)))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.relu(self.conv5(x))\n",
    "        x = self.maxPool(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.dropout(self.relu(self.fc2(x)))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "282b72f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 96, 26, 26])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0229, -0.0044,  0.0065,  ...,  0.0175,  0.0012,  0.0135],\n",
       "        [-0.0085,  0.0136,  0.0106,  ...,  0.0064,  0.0017,  0.0237]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = AlexNet()\n",
    "net(torch.randn(2, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3aafef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "deep-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
