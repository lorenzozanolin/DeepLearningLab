{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "987718c0",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Limits of MLP for image recognition\n",
    "\n",
    "Neural network architecture can leverage domain's specificities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82949faf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "MLP takes a 1D vector as an input. Images are 2D if greyscale, 3D if color.  \n",
    "The color dimension is called the *channel*.\n",
    "\n",
    "By *flattening* the image, we don't lose information, but we lose meta-information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "184dccad",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "mnist_dataset = torchvision.datasets.MNIST('./', download=True,\n",
    "                                           transform=torchvision.transforms.Compose([\n",
    "                                               torchvision.transforms.ToTensor(),\n",
    "                                               torchvision.transforms.Normalize(\n",
    "                                                 (0.1307,), (0.3081,))\n",
    "                                             ]))\n",
    "train_loader = torch.utils.data.DataLoader(dataset=mnist_dataset,\n",
    "                                           batch_size=1, shuffle=False)\n",
    "data, _ = next(iter(train_loader))\n",
    "one_example = data[0]\n",
    "matplotlib.rcParams['figure.figsize'] = [500, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70c53350",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def show(img, title=None):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation='nearest')\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "show(mnist_dataset[0][0], mnist_dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec153d0b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = [100, 1]\n",
    "plt.imshow(one_example.view(1, 1, -1).permute(1, 2, 0), aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a38bfc9",
   "metadata": {},
   "source": [
    "Pixels that should be close from one to another are very far apart\n",
    "\n",
    "We can't recognize the number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3272e107",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Images are natural signals which have 3 properties:\n",
    "\n",
    "* **Stationarity**: Certain motifs are repeated throughout the input.\n",
    "* **Locality**: Nearby points are correlated. Meaning the information is **sparse**.\n",
    "* **Compositionality**: Parts are composed of sub-parts. A deep neural network can decompose layer after layer the information. \n",
    "\n",
    "One huge drawback of MLP is that they are not translation *invariant*. If the images are always centered in the training set, the MLP will only focus on central pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f903112",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "When we compare with random signal, this become clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438389c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(torch.randn(1, 28, 28).permute(1, 2, 0))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "deep-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
