{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Titanic - Machine Learning from Disaster\n","\n","\n","Kaggle link: https://www.kaggle.com/c/titanic\n","\n","W&B link: https://wandb.ai/lorenzozanolin-52/logistic_regression/table?workspace=user-lorenzozanolin-52"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-08T16:00:48.072775Z","iopub.status.busy":"2023-11-08T16:00:48.072344Z","iopub.status.idle":"2023-11-08T16:00:48.085769Z","shell.execute_reply":"2023-11-08T16:00:48.084362Z","shell.execute_reply.started":"2023-11-08T16:00:48.072742Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","#!pip install wandb\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):    # ''\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["Import all the needed library and init Weights and Biases"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T16:00:48.088317Z","iopub.status.busy":"2023-11-08T16:00:48.087851Z","iopub.status.idle":"2023-11-08T16:00:48.330156Z","shell.execute_reply":"2023-11-08T16:00:48.328967Z","shell.execute_reply.started":"2023-11-08T16:00:48.088284Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","torch.manual_seed(0)\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from scipy import stats\n","import pandas as pd\n","\n","import wandb\n","from kaggle_secrets import UserSecretsClient\n","user_secrets = UserSecretsClient()\n","secret_value_0 = user_secrets.get_secret(\"a\")\n","wandb.login(key=secret_value_0)"]},{"cell_type":"markdown","metadata":{},"source":["We first need to read the datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T16:00:48.331995Z","iopub.status.busy":"2023-11-08T16:00:48.331623Z","iopub.status.idle":"2023-11-08T16:00:48.362307Z","shell.execute_reply":"2023-11-08T16:00:48.361081Z","shell.execute_reply.started":"2023-11-08T16:00:48.331952Z"},"trusted":true},"outputs":[],"source":["titanic_training_data = pd.read_csv('/kaggle/input/titanic/train.csv')    #/kaggle/input/titanic/train.csv './titanic/train.csv'\n","titanic_test_data = pd.read_csv('/kaggle/input/titanic/test.csv')\n","titanic_training_data.shape\n","titanic_training_data.head()"]},{"cell_type":"markdown","metadata":{},"source":["Dataframe needs to be cleaned, knowing if some informations are unknown can be very important to determine if someone survived"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T16:00:48.367107Z","iopub.status.busy":"2023-11-08T16:00:48.366583Z","iopub.status.idle":"2023-11-08T16:00:48.375173Z","shell.execute_reply":"2023-11-08T16:00:48.373765Z","shell.execute_reply.started":"2023-11-08T16:00:48.367058Z"},"trusted":true},"outputs":[],"source":["from statsmodels.stats.outliers_influence import variance_inflation_factor  \n","def remove_multicollinearity(df,features):   #we will use it to remove features whom VIF is higher than 20\n","    vif_data=pd.DataFrame()\n","    vif_data[\"Feature\"]=features # names of the features\n","    vif_data[\"VIF\"]=[variance_inflation_factor(df[features].values,i) for i in range(len(features))] # VIF score for each features, higher VIF means higher correlation\n","    return vif_data.sort_values(by=[\"VIF\"]).reset_index(drop=True)\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T16:00:48.377964Z","iopub.status.busy":"2023-11-08T16:00:48.377163Z","iopub.status.idle":"2023-11-08T16:00:48.427170Z","shell.execute_reply":"2023-11-08T16:00:48.425957Z","shell.execute_reply.started":"2023-11-08T16:00:48.377905Z"},"trusted":true},"outputs":[],"source":["def clean_titanic(df, train=True):\n","    df[\"Cabin\"] = df[\"Cabin\"].apply(lambda x: pd.isna(x)).astype(bool)  # will set True for each missing Cabin value, False for each cabin whom value was known\n","    df[\"Embarked\"] = df[\"Embarked\"].apply(lambda x: pd.isna(x)).astype(bool) # same as before\n","    df[\"AgeNan\"] = df[\"Age\"].apply(lambda x: pd.isna(x)).astype(bool) # same as before\n","    df = pd.concat([df, pd.get_dummies(df['Sex'], dtype='bool', prefix='sex_'), pd.get_dummies(df['Pclass'], dtype='bool', prefix='pclass_')], axis=1) # adds new columns to the pre-existing dataframe. pd.get_dummies() encodes categorical variables into one-hot encoded dummy variables\n","    df = df.drop(['PassengerId', 'Name','Ticket','Sex','Pclass'], axis=1) # removes useless features\n","    if train:\n","        df = df.drop(['Survived'], axis=1) # removes last column since we are considering the training set\n","    numeric_features = df.dtypes[(df.dtypes != 'object') & (df.dtypes != 'bool')].index # This results in a list of column names corresponding to the numeric features\n","    df[numeric_features] = df[numeric_features].apply(lambda x: (x - x.mean()) / (x.std())) #mean normalization\n","    df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean()) # fills empty values with the mean\n","    df[\"Fare\"] = df[\"Fare\"].fillna(df[\"Fare\"].mean()) # same\n","    \n","    return df\n","\n","y_data = torch.tensor(titanic_training_data[\"Survived\"].values, dtype=torch.float32)\n","X_data = clean_titanic(titanic_training_data)\n","X_data.head()\n"]},{"cell_type":"markdown","metadata":{},"source":["We then transform the data from numpy (pandas representation) into torch's `Tensor`"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T16:00:48.437710Z","iopub.status.busy":"2023-11-08T16:00:48.437198Z","iopub.status.idle":"2023-11-08T16:00:48.457759Z","shell.execute_reply":"2023-11-08T16:00:48.456356Z","shell.execute_reply.started":"2023-11-08T16:00:48.437662Z"},"trusted":true},"outputs":[],"source":["X_data = torch.tensor(X_data.astype('float').values, dtype=torch.float32)    # create a tensor where each value is a FLOAT\n","X_data\n"]},{"cell_type":"markdown","metadata":{},"source":["Create a `TensorDataset` to get tuple of data and label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T16:00:48.459888Z","iopub.status.busy":"2023-11-08T16:00:48.459474Z","iopub.status.idle":"2023-11-08T16:00:48.473087Z","shell.execute_reply":"2023-11-08T16:00:48.471514Z","shell.execute_reply.started":"2023-11-08T16:00:48.459854Z"},"trusted":true},"outputs":[],"source":["dataset = torch.utils.data.TensorDataset(X_data, y_data)"]},{"cell_type":"markdown","metadata":{},"source":["We then split between the training and validation set"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T16:00:48.476211Z","iopub.status.busy":"2023-11-08T16:00:48.474954Z","iopub.status.idle":"2023-11-08T16:00:48.490799Z","shell.execute_reply":"2023-11-08T16:00:48.489702Z","shell.execute_reply.started":"2023-11-08T16:00:48.476162Z"},"trusted":true},"outputs":[],"source":["training_size = int(0.7 * len(dataset))\n","validation_size = len(dataset) - training_size\n","train, val = torch.utils.data.random_split(dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))\n","data_loader_train = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True) #prima era a 32\n","data_loader_val = torch.utils.data.DataLoader(val, batch_size=10, shuffle=True) #prima era a 10"]},{"cell_type":"markdown","metadata":{},"source":["Layer initialization using Xavier Uniform on the weight and a constant 0 value on the bias"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T16:00:48.495703Z","iopub.status.busy":"2023-11-08T16:00:48.494919Z","iopub.status.idle":"2023-11-08T16:00:48.504730Z","shell.execute_reply":"2023-11-08T16:00:48.503848Z","shell.execute_reply.started":"2023-11-08T16:00:48.495657Z"},"trusted":true},"outputs":[],"source":["import torch.nn.functional as F    \n","\n","def init_my_layer(m, gain=1):\n","    torch.nn.init.xavier_normal_(m.weight, gain)\n","    torch.nn.init.constant_(m.bias, 0)\n","    return m\n","\n","class MyNetwork(nn.Module):\n","    def __init__(self):\n","        super(MyNetwork, self).__init__() \n","        #self.tanh = nn.Tanh()\n","        self.sigmoid = nn.Sigmoid()\n","        self.ln = init_my_layer(nn.Linear(12, 1), nn.init.calculate_gain('sigmoid'))\n","        #self.ln1 = init_my_layer(nn.Linear(12, 5), nn.init.calculate_gain('tanh'))\n","        #self.ln2 = init_my_layer(nn.Linear(5, 1), nn.init.calculate_gain('sigmoid'))\n","        \n","    def forward(self, x):\n","        #x = self.tanh(self.ln1(x))\n","        #x = self.sigmoid(self.ln2(x))\n","        x = self.sigmoid(self.ln(x))\n","        #return F.sigmoid(x) \n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["Create the LinearModel with one Linear layer and Sigmoid applied to the output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T16:00:48.507102Z","iopub.status.busy":"2023-11-08T16:00:48.506353Z","iopub.status.idle":"2023-11-08T16:00:48.525125Z","shell.execute_reply":"2023-11-08T16:00:48.523423Z","shell.execute_reply.started":"2023-11-08T16:00:48.507058Z"},"trusted":true},"outputs":[],"source":["net = MyNetwork() \n","print(list(net.parameters()))"]},{"cell_type":"markdown","metadata":{},"source":["Initialize the network (call it `net`, it would makes things easier later), the loss, the optimizer and write the training loop\n","\n","Don't forget to check the validation loss and save your model at the end of each epoch!"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T16:00:48.528779Z","iopub.status.busy":"2023-11-08T16:00:48.528274Z","iopub.status.idle":"2023-11-08T16:10:13.866650Z","shell.execute_reply":"2023-11-08T16:10:13.865667Z","shell.execute_reply.started":"2023-11-08T16:00:48.528733Z"},"trusted":true},"outputs":[],"source":["from torch.autograd import Variable\n","num_epochs = 500 \n","lr = 3e-3 \n","wandb.init(project=\"logistic_regression\",config={\"lr\": lr, \"epochs\": num_epochs}) \n","criterion = nn.BCELoss()    #binary cross entropy loss\n","\n","o = 'r'\n","\n","if o == 's':\n","    #optimizer = torch.optim.SGD(net.parameters(), lr)\n","    optimizer = torch.optim.SGD(net.parameters(), lr, weight_decay=1e-4)\n","    wandb.log({'optimizer':'SGD'})\n","elif o == 'sg':\n","    #optimizer = torch.optim.SGD(net.parameters(), lr, momentum=0.9)\n","    optimizer = torch.optim.SGD(net.parameters(), lr, momentum=0.9, weight_decay=1e-4)\n","    wandb.log({'optimizer':'SGD-M'})\n","elif o == 'r':\n","    optimizer = torch.optim.RMSprop(net.parameters(), lr)\n","    wandb.log({'optimizer':'RMS'})\n","elif o == 'a':\n","    optimizer = torch.optim.Adam(net.parameters(), lr)\n","    wandb.log({'optimizer':'Adam'})\n","    \n","for epoch in range(num_epochs):\n","    training_loss = 0\n","    #TRAINING LOOP\n","    for X,y in data_loader_train:\n","        optimizer.zero_grad()\n","        y_pred=net(X)\n","        loss=criterion(y_pred,y.reshape(-1, 1))\n","        training_loss += loss\n","        loss.sum().backward()\n","        optimizer.step()\n","    validation_loss = 0\n","    with torch.no_grad():\n","        #VALIDATION LOOP\n","        for X,y in data_loader_val:\n","            y_pred=net(X)\n","            loss=criterion(y_pred,y.reshape(-1, 1))\n","            validation_loss+=loss\n","\n","    print({'epoch':(epoch), 'training_loss': (training_loss/32).item(), 'validation_loss': (validation_loss/10).item()})\n","    wandb.log({'training loss': (training_loss/32).item()}, step=epoch)\n","    wandb.log({'validation loss': (validation_loss/10).item()}, step=epoch)"]},{"cell_type":"markdown","metadata":{},"source":["Now let's see the accuracy on the predictions, then we will create the submission file.\n","\n","This loop computes the prediction on the test dataset and create a submission file\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T16:10:13.868930Z","iopub.status.busy":"2023-11-08T16:10:13.868226Z","iopub.status.idle":"2023-11-08T16:10:13.940700Z","shell.execute_reply":"2023-11-08T16:10:13.939549Z","shell.execute_reply.started":"2023-11-08T16:10:13.868880Z"},"trusted":true},"outputs":[],"source":["titanic_test_data_cleaned = clean_titanic(titanic_test_data, train=False)\n","titanic_data_tensor = torch.tensor(titanic_test_data_cleaned.astype('float').values, dtype=torch.float32)\n","\n","test = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')\n","\n","with torch.no_grad():\n","    net.eval()\n","    test_pred = torch.LongTensor()\n","    for i, data in enumerate(titanic_data_tensor):\n","        output = net(data)\n","        predicted = torch.ge(output, 0.5)\n","        test_pred = torch.cat((test_pred, predicted), dim=0)\n","    out_df = pd.DataFrame(np.c_[titanic_test_data['PassengerId'].values, test_pred.numpy()], columns=['PassengerId', 'Survived'])\n","    out_df.to_csv('submission.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
