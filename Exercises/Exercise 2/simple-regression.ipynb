{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Wine Quality\n",
    "\n",
    "Kaggle link: https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-20T09:27:21.990824Z",
     "iopub.status.busy": "2021-07-20T09:27:21.990322Z",
     "iopub.status.idle": "2021-07-20T09:27:21.998746Z",
     "shell.execute_reply": "2021-07-20T09:27:21.99754Z",
     "shell.execute_reply.started": "2021-07-20T09:27:21.990792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./simple-regression.ipynb\n",
      "./winequality-red.csv\n",
      "./wandb/debug-internal.log\n",
      "./wandb/debug.log\n",
      "./wandb/run-20231013_152213-1mdmbnvn/run-1mdmbnvn.wandb\n",
      "./wandb/run-20231013_152213-1mdmbnvn/logs/debug-internal.log\n",
      "./wandb/run-20231013_152213-1mdmbnvn/logs/debug.log\n",
      "./wandb/run-20231013_152213-1mdmbnvn/files/requirements.txt\n",
      "./wandb/run-20231013_152213-1mdmbnvn/files/output.log\n",
      "./wandb/run-20231013_152213-1mdmbnvn/files/config.yaml\n",
      "./wandb/run-20231013_152213-1mdmbnvn/files/wandb-metadata.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import wandb\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('./'): # '/kaggle/input'\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T09:27:22.001769Z",
     "iopub.status.busy": "2021-07-20T09:27:22.000817Z",
     "iopub.status.idle": "2021-07-20T09:27:22.016019Z",
     "shell.execute_reply": "2021-07-20T09:27:22.01474Z",
     "shell.execute_reply.started": "2021-07-20T09:27:22.001726Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlorenzozanolin-52\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/lorenzozanolin/Library/Mobile Documents/com~apple~CloudDocs/Università/Artifical Intelligence & Cybersecurity/Secondo periodo/Klagenfurt/Machine Learning and Deep Learning/Laboratory/Exercises/Exercise 2/wandb/run-20231013_153847-h2jvr2b3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lorenzozanolin-52/simple_regression/runs/h2jvr2b3' target=\"_blank\">faithful-monkey-4</a></strong> to <a href='https://wandb.ai/lorenzozanolin-52/simple_regression' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lorenzozanolin-52/simple_regression' target=\"_blank\">https://wandb.ai/lorenzozanolin-52/simple_regression</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lorenzozanolin-52/simple_regression/runs/h2jvr2b3' target=\"_blank\">https://wandb.ai/lorenzozanolin-52/simple_regression/runs/h2jvr2b3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/lorenzozanolin-52/simple_regression/runs/h2jvr2b3?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x13d941f70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "import wandb\n",
    "wandb.init(project=\"simple_regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T09:27:22.019074Z",
     "iopub.status.busy": "2021-07-20T09:27:22.018711Z",
     "iopub.status.idle": "2021-07-20T09:27:22.054046Z",
     "shell.execute_reply": "2021-07-20T09:27:22.052743Z",
     "shell.execute_reply.started": "2021-07-20T09:27:22.01904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('./winequality-red.csv')    #'/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv'\n",
    "train_data.head()\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to separate features from target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T09:27:22.056464Z",
     "iopub.status.busy": "2021-07-20T09:27:22.056075Z",
     "iopub.status.idle": "2021-07-20T09:27:22.078596Z",
     "shell.execute_reply": "2021-07-20T09:27:22.077606Z",
     "shell.execute_reply.started": "2021-07-20T09:27:22.05643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1599, 11])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train = train_data.shape[0]   #rows number\n",
    "all_features = train_data.iloc[:, 0:-1] #features excluding the first column (row index) and the last column (quality), which is the label => features are X\n",
    "all_features = all_features.apply(lambda x: (x - x.mean()) / (x.std())) #normalization\n",
    "train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float32)   #create the tensor containing the features\n",
    "\n",
    "train_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T09:27:22.07993Z",
     "iopub.status.busy": "2021-07-20T09:27:22.079658Z",
     "iopub.status.idle": "2021-07-20T09:27:22.088282Z",
     "shell.execute_reply": "2021-07-20T09:27:22.087172Z",
     "shell.execute_reply.started": "2021-07-20T09:27:22.079904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [5],\n",
       "       [5],\n",
       "       ...,\n",
       "       [6],\n",
       "       [5],\n",
       "       [6]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trains_labels = train_data.quality.values.reshape(-1, 1)\n",
    "trains_labels   #labels representing the quality of the wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T09:27:22.090275Z",
     "iopub.status.busy": "2021-07-20T09:27:22.089806Z",
     "iopub.status.idle": "2021-07-20T09:27:22.107085Z",
     "shell.execute_reply": "2021-07-20T09:27:22.105645Z",
     "shell.execute_reply.started": "2021-07-20T09:27:22.090224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7878],\n",
       "        [-0.7878],\n",
       "        [-0.7878],\n",
       "        ...,\n",
       "        [ 0.4508],\n",
       "        [-0.7878],\n",
       "        [ 0.4508]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trains_mean = trains_labels.mean()\n",
    "trains_std = trains_labels.std()\n",
    "trains_labels = (trains_labels - trains_mean) / trains_std  #normalization\n",
    "train_labels = torch.tensor(trains_labels,          #tensor containing the normalized training labels\n",
    "                            dtype=torch.float32)\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the weight of the linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T09:27:22.108789Z",
     "iopub.status.busy": "2021-07-20T09:27:22.108457Z",
     "iopub.status.idle": "2021-07-20T09:27:22.116208Z",
     "shell.execute_reply": "2021-07-20T09:27:22.114731Z",
     "shell.execute_reply.started": "2021-07-20T09:27:22.10876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.6282, -1.6004,  1.6385, -1.0293, -0.5036, -0.0814,  0.9035, -1.2022,\n",
       "         2.7352,  0.6013, -1.1299], requires_grad=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = train_features.shape[1] #-2\n",
    "linear_weights = torch.randn((n_features),requires_grad=True) # TODO, initialize a random tensor of weights, one weight for each feature\n",
    "linear_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T09:27:22.11778Z",
     "iopub.status.busy": "2021-07-20T09:27:22.117448Z",
     "iopub.status.idle": "2021-07-20T09:27:22.446969Z",
     "shell.execute_reply": "2021-07-20T09:27:22.445827Z",
     "shell.execute_reply.started": "2021-07-20T09:27:22.11775Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/lorenzozanolin/Library/Mobile Documents/com~apple~CloudDocs/Università/Artifical Intelligence & Cybersecurity/Secondo periodo/Klagenfurt/Machine Learning and Deep Learning/Laboratory/Exercises/Exercise 2/simple-regression.ipynb Cella 15\u001b[0m line \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzozanolin/Library/Mobile%20Documents/com~apple~CloudDocs/Universita%CC%80/Artifical%20Intelligence%20%26%20Cybersecurity/Secondo%20periodo/Klagenfurt/Machine%20Learning%20and%20Deep%20Learning/Laboratory/Exercises/Exercise%202/simple-regression.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_iterations):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzozanolin/Library/Mobile%20Documents/com~apple~CloudDocs/Universita%CC%80/Artifical%20Intelligence%20%26%20Cybersecurity/Secondo%20periodo/Klagenfurt/Machine%20Learning%20and%20Deep%20Learning/Laboratory/Exercises/Exercise%202/simple-regression.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     predictions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul(train_features,linear_weights)    \u001b[39m#calculate the prediction, i.e. X(train features) * weights \u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lorenzozanolin/Library/Mobile%20Documents/com~apple~CloudDocs/Universita%CC%80/Artifical%20Intelligence%20%26%20Cybersecurity/Secondo%20periodo/Klagenfurt/Machine%20Learning%20and%20Deep%20Learning/Laboratory/Exercises/Exercise%202/simple-regression.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     loss(predictions,train_labels)   \u001b[39m#loss calculation\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzozanolin/Library/Mobile%20Documents/com~apple~CloudDocs/Universita%CC%80/Artifical%20Intelligence%20%26%20Cybersecurity/Secondo%20periodo/Klagenfurt/Machine%20Learning%20and%20Deep%20Learning/Laboratory/Exercises/Exercise%202/simple-regression.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward() \u001b[39m#derivate calc\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzozanolin/Library/Mobile%20Documents/com~apple~CloudDocs/Universita%CC%80/Artifical%20Intelligence%20%26%20Cybersecurity/Secondo%20periodo/Klagenfurt/Machine%20Learning%20and%20Deep%20Learning/Laboratory/Exercises/Exercise%202/simple-regression.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/loss.py:533\u001b[0m, in \u001b[0;36mMSELoss.__init__\u001b[0;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, size_average\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, reduce\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, reduction: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 533\u001b[0m     \u001b[39msuper\u001b[39;49m(MSELoss, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(size_average, reduce, reduction)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/loss.py:23\u001b[0m, in \u001b[0;36m_Loss.__init__\u001b[0;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39msuper\u001b[39m(_Loss, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m     22\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreduction: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39;49mlegacy_get_string(size_average, reduce)\n\u001b[1;32m     24\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreduction \u001b[39m=\u001b[39m reduction\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/_reduction.py:35\u001b[0m, in \u001b[0;36mlegacy_get_string\u001b[0;34m(size_average, reduce, emit_warning)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     reduce \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mand\u001b[39;00m reduce:\n\u001b[1;32m     36\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[39melif\u001b[39;00m reduce:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "num_iterations = 512\n",
    "lr = 1e-3\n",
    "loss = nn.MSELoss\n",
    "for i in range(num_iterations):\n",
    "    predictions = torch.matmul(train_features,linear_weights)    #calculate the prediction, i.e. X(train features) * weights \n",
    "    loss(predictions,train_labels)   #loss calculation\n",
    "    loss.backward() #derivate calc\n",
    "    \n",
    "    with torch.no_grad:\n",
    "        linear_weights-=lr*linear_weights.grad  #backprop\n",
    "    linear_weights.requires_grad = True\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the real predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-20T09:27:22.449495Z",
     "iopub.status.busy": "2021-07-20T09:27:22.449118Z",
     "iopub.status.idle": "2021-07-20T09:27:22.459333Z",
     "shell.execute_reply": "2021-07-20T09:27:22.457917Z",
     "shell.execute_reply.started": "2021-07-20T09:27:22.449447Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = (predictions * trains_std) + trains_mean  #denormalization \n",
    "predictions #resulting labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our predictions seem very close to the ground truth!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To go further**: Stochastic Gradient Descent is not the optimal algorithm in terms of convergeance.\n",
    "If you are curious, you can read this nice article about an improvement to SGD, momentum and try to implement it: https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
