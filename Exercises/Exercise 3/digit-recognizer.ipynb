{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Kaggle link : https://www.kaggle.com/code/lorenzozanolin/digit-recognizer\n\nW&B link: https://wandb.ai/lorenzozanolin-52/digit_recognizer/table?workspace=user-lorenzozanolin-52","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-12-23T18:27:49.794464Z","iopub.execute_input":"2023-12-23T18:27:49.795279Z","iopub.status.idle":"2023-12-23T18:27:50.198858Z","shell.execute_reply.started":"2023-12-23T18:27:49.795239Z","shell.execute_reply":"2023-12-23T18:27:50.197939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We need to import Torch's libraries","metadata":{}},{"cell_type":"code","source":"import torchvision\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport matplotlib.pyplot as plt\nimport wandb\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"a\")\nwandb.login(key=secret_value_0)\nwandb.init(project='digit_recognizer', save_code=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T18:27:50.200908Z","iopub.execute_input":"2023-12-23T18:27:50.201410Z","iopub.status.idle":"2023-12-23T18:28:26.831095Z","shell.execute_reply.started":"2023-12-23T18:27:50.201373Z","shell.execute_reply":"2023-12-23T18:28:26.830114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data preparation\n\nA custom dataset which uses the CSV from Kaggle, avoid downloading the dataset from internet","metadata":{}},{"cell_type":"code","source":"class MyMNISTDataset(Dataset):\n    \n    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=False):#torch.cuda.is_available()):\n        # read the data\n        df = pd.read_csv(file_path)\n        # for test data we don't have any target\n        # MNIST images are 28 by 28, grey colors\n        if test_data:\n            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n            self.y = None\n        else:\n            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n            self.y = torch.from_numpy(df.iloc[:,0].values)\n        self.transform = transform\n       # self.use_gpu = use_gpu\n    \n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        data = self.transform(self.X[idx])\n        if self.y is not None:\n            target = self.y[idx]\n            #if self.use_gpu:\n            #    data = data.cuda()\n            #    target = target.cuda()\n            return data, target\n        else:\n            #if self.use_gpu:\n            #    data = data.cuda()\n            return data","metadata":{"execution":{"iopub.status.busy":"2023-12-23T18:28:26.832268Z","iopub.execute_input":"2023-12-23T18:28:26.832567Z","iopub.status.idle":"2023-12-23T18:28:27.469105Z","shell.execute_reply.started":"2023-12-23T18:28:26.832543Z","shell.execute_reply":"2023-12-23T18:28:27.468205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformations=transforms.Compose([transforms.ToPILImage(), \n                                    transforms.ToTensor(), \n                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])\n\ntrain_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)\ntest_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)\n\n# create data loader for train, validation and test set\nbatch_size = 20\ncuda_args = {'num_workers': 1, 'pin_memory': True, 'shuffle': False}\nnum_train = len(train_dataset)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(0.2 * num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\n# define samplers for obtaining training and validation batches\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\n# prepare data loaders\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n    sampler=train_sampler, **cuda_args)\nvalid_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n    sampler=valid_sampler, **cuda_args)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, **cuda_args)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T18:28:27.470678Z","iopub.execute_input":"2023-12-23T18:28:27.471442Z","iopub.status.idle":"2023-12-23T18:28:32.916291Z","shell.execute_reply.started":"2023-12-23T18:28:27.471404Z","shell.execute_reply":"2023-12-23T18:28:32.915361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MLP\n\n### Define model architecture\nYou need to reach at least 70% accuracy on the test set","metadata":{}},{"cell_type":"code","source":"class Net(nn.Module):    \n    def __init__(self):\n        super(Net, self).__init__()\n        # we will use the following net: 784 -> 512 -> 10\n        self.fc1 = nn.Linear(28*28,512)\n        self.fc2 = nn.Linear(512,10)\n        self.dropout = nn.Dropout(0.2) #dropout to avoid overfitting\n        \n    def forward(self, x):\n        x = x.to(device='cuda').view(-1, 28 * 28) # flatten image input\n        #ReLU + dropout for each layer\n        x = F.relu(self.fc1(x))  \n        x = self.dropout(x)\n    \n        #output\n        x = self.fc2(x)\n        return x","metadata":{"ExecuteTime":{"end_time":"2023-12-08T18:15:01.793286Z","start_time":"2023-12-08T18:15:01.780071Z"},"execution":{"iopub.status.busy":"2023-12-23T18:28:32.918959Z","iopub.execute_input":"2023-12-23T18:28:32.919236Z","iopub.status.idle":"2023-12-23T18:28:33.502063Z","shell.execute_reply.started":"2023-12-23T18:28:32.919205Z","shell.execute_reply":"2023-12-23T18:28:33.501069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Init the model and put it on GPU/TPU","metadata":{}},{"cell_type":"code","source":"#let use the model on the GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\nmodel = Net().to(device)\n\nprint(model)\n\nlr = 0.1\nwandb.log({'lr': lr})\n\n#We will use Cross-Entropy as Loss function\ncriterion = nn.CrossEntropyLoss()\n\no = 's'\n\nif o == 's':\n    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n    wandb.log({'optimizer':'SGD'})\nelif o == 'a':\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    wandb.log({'optimizer':'Adam'})","metadata":{"execution":{"iopub.status.busy":"2023-12-23T18:28:33.506288Z","iopub.execute_input":"2023-12-23T18:28:33.506852Z","iopub.status.idle":"2023-12-23T18:28:35.609393Z","shell.execute_reply.started":"2023-12-23T18:28:33.506822Z","shell.execute_reply":"2023-12-23T18:28:35.608330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training loop\nLog the accuracy and the loss to wandb","metadata":{}},{"cell_type":"code","source":"# number of epochs to train the model\nn_epochs = 30\nmean_train_losses = []\nmean_valid_losses = []\nvalid_acc_list = []\nwandb.log({'num_epochs': n_epochs})\n\n# initialize tracker for minimum validation loss\nfor epoch in range(n_epochs):\n    train_losses = []\n    valid_losses = []\n    \n    ###################\n    # train the model #\n    ###################\n    model.train() # prep model for training\n    for data, target in train_loader:\n        #pass the data and the target on the GPU\n        data=data.to(device)\n        target=target.to(device)\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update running training loss\n        train_losses.append(loss.item())\n        \n        \n    ######################    \n    # validate the model #\n    ######################\n    model.eval() # prep model for evaluation\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data, target in valid_loader:\n            #pass the data and the target on the GPU\n            data=data.to(device)\n            target=target.to(device)\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = model(data)\n            # calculate the loss\n            loss = criterion(output, target)\n            # update running validation loss \n            valid_losses.append(loss.item())\n            \n            _, predicted = torch.max(output.data, 1)\n            correct += (predicted == target).sum().item()\n            total += target.size(0)\n\n    mean_train_losses.append(np.mean(train_losses))\n    mean_valid_losses.append(np.mean(valid_losses))\n    \n    accuracy = 100*correct/total\n    valid_acc_list.append(accuracy)\n    print('epoch : {}, train loss : {:.4f}, valid loss : {:.4f}, valid acc : {:.2f}%'\\\n         .format(epoch+1, np.mean(train_losses), np.mean(valid_losses), accuracy))\n\nwandb.log({'train_loss':mean_train_losses[-1]})\nwandb.log({'val_loss':mean_valid_losses[-1]})\nwandb.log({'val_accuracy':valid_acc_list[-1]})","metadata":{"execution":{"iopub.status.busy":"2023-12-23T18:28:35.613725Z","iopub.execute_input":"2023-12-23T18:28:35.614042Z","iopub.status.idle":"2023-12-23T18:33:51.703381Z","shell.execute_reply.started":"2023-12-23T18:28:35.614013Z","shell.execute_reply":"2023-12-23T18:33:51.702312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Make prediction\nAnd submit to Kaggle for grading","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    model.eval()\n    test_pred = torch.LongTensor()\n    for i, data in enumerate(test_loader):\n        data=data.to(device)\n        output = model(data)\n        _, predicted = torch.max(output.data, 1)\n        predicted = predicted.cpu()\n        test_pred = torch.cat((test_pred, predicted), dim=0)\n    out_df = pd.DataFrame(np.c_[np.arange(1, len(test_dataset)+1)[:,None], test_pred.numpy()], columns=['ImageId', 'Label'])\n    out_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T18:33:51.704940Z","iopub.execute_input":"2023-12-23T18:33:51.705313Z","iopub.status.idle":"2023-12-23T18:34:00.764954Z","shell.execute_reply.started":"2023-12-23T18:33:51.705274Z","shell.execute_reply":"2023-12-23T18:34:00.764020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Top 10 misclassified images by class probability","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\nunshuffle_train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                           batch_size=batch_size, shuffle=False)\nwith torch.no_grad():\n    model.eval()\n    missclasified = torch.DoubleTensor()\n    for batch_idx, (data, target) in enumerate(unshuffle_train_loader):\n        output = model(data)\n        prob, predicted = torch.max(output.data, 1)\n        predicted = predicted.cpu()\n        target = target.cpu()\n        prob = prob.cpu().double()\n        missclassified_prob = torch.where(predicted == target, 0., prob)\n        missclasified = torch.cat((missclasified, missclassified_prob), dim=0)\n    most_misclassified = torch.argsort(missclasified, descending=True)\n    top_ten_misclassified = most_misclassified[:10]","metadata":{"execution":{"iopub.status.busy":"2023-12-23T18:34:00.766206Z","iopub.execute_input":"2023-12-23T18:34:00.766574Z","iopub.status.idle":"2023-12-23T18:34:12.240882Z","shell.execute_reply.started":"2023-12-23T18:34:00.766538Z","shell.execute_reply":"2023-12-23T18:34:12.239910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for misclassified in top_ten_misclassified:\n    plt.imshow(train_dataset[misclassified][0].cpu().reshape(28,28))\n    with torch.no_grad():\n        data, target = train_dataset[misclassified]\n        data = data.reshape(1, 1, 28,28)\n        output = model(data)\n        _, predicted = torch.max(output.data, 1)\n        plt.title(f'Predicted: {predicted.item()}, Ground truth: {target}')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-23T18:34:12.242059Z","iopub.execute_input":"2023-12-23T18:34:12.242529Z","iopub.status.idle":"2023-12-23T18:34:15.547605Z","shell.execute_reply.started":"2023-12-23T18:34:12.242493Z","shell.execute_reply":"2023-12-23T18:34:15.546689Z"},"trusted":true},"execution_count":null,"outputs":[]}]}