{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3649,"databundleVersionId":46718,"sourceType":"competition"}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nfrom tqdm.notebook import trange, tqdm\nimport wandb\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"a\")\nwandb.login(key=secret_value_0)\nwandb.init(project='object_recognition', save_code=True)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-01-22T15:42:19.843975Z","iopub.execute_input":"2024-01-22T15:42:19.844229Z","iopub.status.idle":"2024-01-22T15:42:56.208198Z","shell.execute_reply.started":"2024-01-22T15:42:19.844206Z","shell.execute_reply":"2024-01-22T15:42:56.207122Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/cifar-10/trainLabels.csv\n/kaggle/input/cifar-10/sampleSubmission.csv\n/kaggle/input/cifar-10/test.7z\n/kaggle/input/cifar-10/train.7z\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlorenzozanolin-52\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240122_154224-8bpzrdaf</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/lorenzozanolin-52/object_recognition/runs/8bpzrdaf' target=\"_blank\">bright-lion-2</a></strong> to <a href='https://wandb.ai/lorenzozanolin-52/object_recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/lorenzozanolin-52/object_recognition' target=\"_blank\">https://wandb.ai/lorenzozanolin-52/object_recognition</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/lorenzozanolin-52/object_recognition/runs/8bpzrdaf' target=\"_blank\">https://wandb.ai/lorenzozanolin-52/object_recognition/runs/8bpzrdaf</a>"},"metadata":{}},{"execution_count":1,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/lorenzozanolin-52/object_recognition/runs/8bpzrdaf?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7ca46c2552d0>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Import everything needed","metadata":{}},{"cell_type":"code","source":"import glob\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport collections\nimport math\nimport os\nimport shutil\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision\nfrom torchvision import datasets, transforms\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2024-01-22T15:42:56.209948Z","iopub.execute_input":"2024-01-22T15:42:56.211074Z","iopub.status.idle":"2024-01-22T15:43:01.136220Z","shell.execute_reply.started":"2024-01-22T15:42:56.211035Z","shell.execute_reply":"2024-01-22T15:43:01.135125Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Unzip datasets","metadata":{}},{"cell_type":"code","source":"!pip install py7zr","metadata":{"execution":{"iopub.status.busy":"2024-01-22T15:43:17.554223Z","iopub.execute_input":"2024-01-22T15:43:17.554563Z","iopub.status.idle":"2024-01-22T15:43:30.319371Z","shell.execute_reply.started":"2024-01-22T15:43:17.554529Z","shell.execute_reply":"2024-01-22T15:43:30.318331Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: py7zr in /opt/conda/lib/python3.10/site-packages (0.20.8)\nRequirement already satisfied: texttable in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.7.0)\nRequirement already satisfied: pycryptodomex>=3.16.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (3.20.0)\nRequirement already satisfied: pyzstd>=0.15.9 in /opt/conda/lib/python3.10/site-packages (from py7zr) (0.15.9)\nRequirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.1.0)\nRequirement already satisfied: pybcj<1.1.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.0.2)\nRequirement already satisfied: multivolumefile>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from py7zr) (0.2.3)\nRequirement already satisfied: inflate64<1.1.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.0.0)\nRequirement already satisfied: brotli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.1.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from py7zr) (5.9.3)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# WARNING: It can take a lot of time to uncompress!","metadata":{}},{"cell_type":"code","source":"!python -m py7zr x /kaggle/input/cifar-10/train.7z","metadata":{"execution":{"iopub.status.busy":"2024-01-22T15:44:28.325653Z","iopub.execute_input":"2024-01-22T15:44:28.326258Z","iopub.status.idle":"2024-01-22T15:45:27.315238Z","shell.execute_reply.started":"2024-01-22T15:44:28.326215Z","shell.execute_reply":"2024-01-22T15:45:27.314203Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"!python -m py7zr x /kaggle/input/cifar-10/test.7z","metadata":{"execution":{"iopub.status.busy":"2024-01-22T15:45:27.316771Z","iopub.execute_input":"2024-01-22T15:45:27.317121Z","iopub.status.idle":"2024-01-22T16:04:23.055935Z","shell.execute_reply.started":"2024-01-22T15:45:27.317080Z","shell.execute_reply":"2024-01-22T16:04:23.054953Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/working/'","metadata":{"execution":{"iopub.status.busy":"2024-01-22T16:04:23.057341Z","iopub.execute_input":"2024-01-22T16:04:23.058210Z","iopub.status.idle":"2024-01-22T16:04:23.542978Z","shell.execute_reply.started":"2024-01-22T16:04:23.058170Z","shell.execute_reply":"2024-01-22T16:04:23.542070Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def read_csv_labels(fname):\n    \"\"\"Read `fname` to return a filename to label dictionary.\"\"\"\n    with open(fname, 'r') as f:\n        # Skip the file header line (column name)\n        lines = f.readlines()[1:]\n    tokens = [l.rstrip().split(',') for l in lines]\n    return dict(((name, label) for name, label in tokens))\n\nlabels = read_csv_labels(os.path.join(data_dir, '/kaggle/input/cifar-10/trainLabels.csv'))\nprint(f'Number training examples: {len(labels)}')\nprint(f'Number classes: {len(set(labels.values()))}')","metadata":{"execution":{"iopub.status.busy":"2024-01-22T16:04:23.544508Z","iopub.execute_input":"2024-01-22T16:04:23.544851Z","iopub.status.idle":"2024-01-22T16:04:24.280934Z","shell.execute_reply.started":"2024-01-22T16:04:23.544811Z","shell.execute_reply":"2024-01-22T16:04:24.280008Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Number training examples: 50000\nNumber classes: 10\n","output_type":"stream"}]},{"cell_type":"code","source":"def copyfile(filename, target_dir):\n    \"\"\"Copy a file into a target directory.\"\"\"\n    os.makedirs(target_dir, exist_ok=True)\n    shutil.copy(filename, target_dir)\n\ndef reorg_train_valid(data_dir, labels, valid_ratio):\n    \"\"\"Split the validation set out of the original training set.\"\"\"\n    # The number of examples of the class that has the fewest examples in the\n    # training dataset\n    n = collections.Counter(labels.values()).most_common()[-1][1]\n    # The number of examples per class for the validation set\n    n_valid_per_label = max(1, math.floor(n * valid_ratio))\n    label_count = {}\n    for train_file in os.listdir(os.path.join(data_dir, 'train')):\n        label = labels[train_file.split('.')[0]]\n        fname = os.path.join(data_dir, 'train', train_file)\n        copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                     'train_valid', label))\n        if label not in label_count or label_count[label] < n_valid_per_label:\n            copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                         'valid', label))\n            label_count[label] = label_count.get(label, 0) + 1\n        else:\n            copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                         'train', label))\n    return n_valid_per_label\n\ndef reorg_test(data_dir):\n    \"\"\"Organize the testing set for data loading during prediction.\"\"\"\n    for test_file in os.listdir(os.path.join(data_dir, 'test')):\n        copyfile(os.path.join(data_dir, 'test', test_file),\n                 os.path.join(data_dir, 'train_valid_test', 'test',\n                              'unknown'))\n        \ndef reorg_cifar10_data(data_dir, valid_ratio):\n    labels = read_csv_labels('/kaggle/input/cifar-10/trainLabels.csv')\n    reorg_train_valid(data_dir, labels, valid_ratio)\n    reorg_test(data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-01-22T16:04:24.286253Z","iopub.execute_input":"2024-01-22T16:04:24.286642Z","iopub.status.idle":"2024-01-22T16:04:24.853277Z","shell.execute_reply.started":"2024-01-22T16:04:24.286606Z","shell.execute_reply":"2024-01-22T16:04:24.852369Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\nvalid_ratio = 0.1\nreorg_cifar10_data(data_dir, valid_ratio)\nwandb.log({'batch_size': batch_size})","metadata":{"execution":{"iopub.status.busy":"2024-01-22T16:04:24.854528Z","iopub.execute_input":"2024-01-22T16:04:24.854882Z","iopub.status.idle":"2024-01-22T16:05:28.467008Z","shell.execute_reply.started":"2024-01-22T16:04:24.854842Z","shell.execute_reply":"2024-01-22T16:05:28.466098Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Transformations\nWe will do some Image Augmentation:","metadata":{}},{"cell_type":"code","source":"transform_train = torchvision.transforms.Compose([\n    transforms.RandomCrop(32, padding=4),  #Random crop can help to make the NN invariant to the position of the element\n    transforms.RandomHorizontalFlip(),  #we will use horizontal flip\n    torchvision.transforms.ToTensor(), #transform the image into a tensor\n    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],  #each channel (3) will be normalized using the mean (first tuple) and the std (second tuple)\n                                     [0.2023, 0.1994, 0.2010])\n])\n\ntransform_test = torchvision.transforms.Compose([  #since it is the dataset, we will not do data augmentation, other than normalization\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465], #each channel (3) will be normalized using the mean (first tuple) and the std (second tuple)\n                                     [0.2023, 0.1994, 0.2010])]) ","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-01-22T16:19:24.624310Z","iopub.execute_input":"2024-01-22T16:19:24.625189Z","iopub.status.idle":"2024-01-22T16:19:25.181376Z","shell.execute_reply.started":"2024-01-22T16:19:24.625154Z","shell.execute_reply":"2024-01-22T16:19:25.180489Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_ds, train_valid_ds = [torchvision.datasets.ImageFolder(\n    os.path.join(data_dir, 'train_valid_test', folder),\n    transform=transform_train) for folder in ['train', 'train_valid']]\n\nvalid_ds, test_ds = [torchvision.datasets.ImageFolder(\n    os.path.join(data_dir, 'train_valid_test', folder),\n    transform=transform_test) for folder in ['valid', 'test']]\n\ntrain_iter, train_valid_iter = [torch.utils.data.DataLoader(\n    dataset, batch_size, shuffle=True, drop_last=True)\n    for dataset in (train_ds, train_valid_ds)]\n\nvalid_iter = torch.utils.data.DataLoader(valid_ds, batch_size, shuffle=False,\n                                         drop_last=True)\n\ntest_iter = torch.utils.data.DataLoader(test_ds, batch_size, shuffle=False,\n                                        drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-22T16:19:27.911250Z","iopub.execute_input":"2024-01-22T16:19:27.912020Z","iopub.status.idle":"2024-01-22T16:19:30.518374Z","shell.execute_reply.started":"2024-01-22T16:19:27.911985Z","shell.execute_reply":"2024-01-22T16:19:30.517461Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### ResNet18 Fine Tuning\nWe will now use transfer learning on a pretrained net (ResNet18) modifying the last layer to predict the classes of the images.","metadata":{}},{"cell_type":"code","source":"net = torchvision.models.resnet18(pretrained=True)  #load the net with pretrained weigths\nnet.fc = nn.Linear(net.fc.in_features, 10)  #modify the fc layer to have an output of 10 classes\nnn.init.xavier_normal_(net.fc.weight)  #random initialization of the weights \nnn.init.constant_(net.fc.bias, 0);  # bias\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'  #we want to move the net on the GPU\nnet = net.to(device)\nif device == 'cuda':\n    net = torch.nn.DataParallel(net) # if multiple GPUs use them","metadata":{"execution":{"iopub.status.busy":"2024-01-22T16:19:33.674412Z","iopub.execute_input":"2024-01-22T16:19:33.675155Z","iopub.status.idle":"2024-01-22T16:19:35.093801Z","shell.execute_reply.started":"2024-01-22T16:19:33.675120Z","shell.execute_reply":"2024-01-22T16:19:35.092917Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 212MB/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now, we will use:\n- Cross Entropy as the $Loss function$\n- Adam with Reduced LR as $Optimizer$","metadata":{}},{"cell_type":"code","source":"lr = 1e-4\nwandb.log({'optimizer': 'Adam'})\nwandb.log({'lr': lr})\ncriterion = nn.CrossEntropyLoss(label_smoothing=0.1)\noptimizer = torch.optim.AdamW(net.parameters(), lr=lr, weight_decay=0.0001)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, verbose=True, min_lr=1e-5, factor=0.5)","metadata":{"execution":{"iopub.status.busy":"2024-01-22T16:19:39.039634Z","iopub.execute_input":"2024-01-22T16:19:39.039995Z","iopub.status.idle":"2024-01-22T16:19:39.657848Z","shell.execute_reply.started":"2024-01-22T16:19:39.039967Z","shell.execute_reply":"2024-01-22T16:19:39.656931Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Let us train the net!","metadata":{}},{"cell_type":"code","source":"# we will train for 10 epochs\nepochs = 10\nwandb.log({'epochs': epochs})\n\nfor epoch in trange(epochs):\n    mean_train_losses = []\n    mean_valid_losses = []\n    valid_acc_list = []\n    train_losses = []\n    valid_losses = []\n    total = 0\n    val_acc = 0\n    # TRAINING\n    for X, y in tqdm(train_iter):\n        tr_loss = 0\n        X = X.to(device)  #move data on the GPU\n        y = y.to(device)\n        y_pred = net(X)  #calculate the value using the net, y_pred in this case will be an array of 10 values (probability for each class)\n        loss = criterion(y_pred, y)  # calculate the loss wrt the ground truth\n        \n        # zero the gradients before running\n        # the backward pass.\n        optimizer.zero_grad()\n\n        # Backward pass to compute the gradient\n        # of loss w.r.t our learnable params. \n        loss.backward()\n\n        # Update params\n        optimizer.step()\n        \n        train_losses.append(loss.item())\n        \n    # VALIDATION\n    with torch.no_grad():\n        net.eval()  # put network in train mode for Dropout and Batch Normalization\n        \n        for X, y in tqdm(valid_iter):\n            X = X.to(device)\n            y = y.to(device)\n            y_pred = net(X)\n            loss = criterion(y_pred, y)\n            _, predicted = torch.max(y_pred, 1)\n            val_acc += (y == predicted).sum().float()\n            valid_losses.append(loss.item())\n            total += len(y)\n\n    mean_train_losses.append(np.mean(train_losses))\n    mean_valid_losses.append(np.mean(valid_losses))\n    \n    accuracy = 100*val_acc/total\n    valid_acc_list.append(accuracy)\n    \n    print('epoch : {}, train loss : {:.4f}, valid loss : {:.4f}, valid acc : {:.2f}%'\\\n         .format(epoch+1, np.mean(train_losses), np.mean(valid_losses), accuracy))\n    \n    wandb.log({'train_loss':mean_train_losses[-1]})\n    wandb.log({'val_loss':mean_valid_losses[-1]})\n    wandb.log({'val_accuracy':valid_acc_list[-1]})","metadata":{"execution":{"iopub.status.busy":"2024-01-22T16:23:54.915134Z","iopub.execute_input":"2024-01-22T16:23:54.915864Z","iopub.status.idle":"2024-01-22T16:33:26.050427Z","shell.execute_reply.started":"2024-01-22T16:23:54.915832Z","shell.execute_reply":"2024-01-22T16:33:26.049373Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c6589031206416784db925405054fe3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/703 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5036fd8709424631b12ddd05acf4b5b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/78 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"841da1af6efe4421ab8d634705a063a0"}},"metadata":{}},{"name":"stdout","text":"epoch : 1, train loss : 1.2007, valid loss : 1.1350, valid acc : 71.77%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/703 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5eae23fe96454b7ba053b99c76b1cfeb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/78 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"392530be314d4756b2d565d802288924"}},"metadata":{}},{"name":"stdout","text":"epoch : 2, train loss : 1.0839, valid loss : 1.0625, valid acc : 74.82%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/703 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfc39067bc354b539c17af19754255e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/78 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58b8de0fb645464798af0316e8cacdb1"}},"metadata":{}},{"name":"stdout","text":"epoch : 3, train loss : 1.0300, valid loss : 0.9986, valid acc : 77.52%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/703 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5cfac71234a4986b7e3e5aca551b9aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/78 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"953ef096dded403aae705131ab247db6"}},"metadata":{}},{"name":"stdout","text":"epoch : 4, train loss : 0.9870, valid loss : 0.9658, valid acc : 79.41%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/703 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf084b79dbc9416381c7a4e60702a5eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/78 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c826f67e13e47d7bfed7c7c19d2c90d"}},"metadata":{}},{"name":"stdout","text":"epoch : 5, train loss : 0.9553, valid loss : 0.9439, valid acc : 80.43%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/703 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"573009180b554c89a2c46bb3f8bf67e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/78 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcfcfa7311284caab7455083cdb25b1b"}},"metadata":{}},{"name":"stdout","text":"epoch : 6, train loss : 0.9259, valid loss : 0.9402, valid acc : 81.39%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/703 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e142b3d75e584b10b94dfe92379d01c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/78 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b844c52d3fea45a9a35d5dc87437e614"}},"metadata":{}},{"name":"stdout","text":"epoch : 7, train loss : 0.8971, valid loss : 0.9372, valid acc : 81.01%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/703 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d31a8ecb1854ce486132a6108e8f331"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/78 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddd9b7fe9a554c6a8edf536b96426211"}},"metadata":{}},{"name":"stdout","text":"epoch : 8, train loss : 0.8744, valid loss : 0.9169, valid acc : 82.13%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/703 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6911f71126343c690449cb257eaab45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/78 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79554b3ef7694fa9836f5e4bd1ca97d6"}},"metadata":{}},{"name":"stdout","text":"epoch : 9, train loss : 0.8548, valid loss : 0.9026, valid acc : 82.31%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/703 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d0ee33a0090404aa335b28139e22aba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/78 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83f1659035bc4c229b766b4eef501c5e"}},"metadata":{}},{"name":"stdout","text":"epoch : 10, train loss : 0.8411, valid loss : 0.9117, valid acc : 82.11%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Submission generation\nWe will generate the submission.csv file based on the test set","metadata":{}},{"cell_type":"code","source":"preds = []\n\nnet.eval()\nwith torch.no_grad():\n    for X, _ in test_iter:\n        X = X.to(device)\n        preds.extend(net(X).argmax(dim=1).type(torch.int32).cpu().numpy())\nids = list(range(1, len(test_ds)+1))\nids.sort(key=lambda x: str(x))\ndf = pd.DataFrame({'id': ids, 'label': preds})\ndf['label'] = df['label'].apply(lambda x: train_ds.classes[x])\ndf.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-22T11:32:53.949158Z","iopub.execute_input":"2024-01-22T11:32:53.949549Z","iopub.status.idle":"2024-01-22T11:36:21.804623Z","shell.execute_reply.started":"2024-01-22T11:32:53.949521Z","shell.execute_reply":"2024-01-22T11:36:21.803650Z"},"trusted":true},"execution_count":29,"outputs":[]}]}